{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from src.Runner2048 import Game\n",
    "from model_class import DQN\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_state(board):\n",
    "  board_flat = torch.LongTensor(board)\n",
    "  board_flat = nn.functional.one_hot(board_flat, num_classes=16).float().flatten()\n",
    "  board_flat = board_flat.reshape(1, 4, 4, 16).permute(0, 3, 1, 2)\n",
    "  return board_flat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MINIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from torch import nn, optim, tensor\n",
    "action_dict = {0:'U', 1:'R', 2:'D', 3:'L'}\n",
    "# Inputs\n",
    "#  The game\n",
    "#  The policy that was used to make the move\n",
    "#  The Q-value from the action to get to this state\n",
    "def minimax(game, policy, value_from_action=0, depth=3, my_turn=True):\n",
    "\n",
    "    best_action = None\n",
    "\n",
    "\n",
    "    # See if the game is over or we've reached the depth limit\n",
    "    if depth <= 1 or game.check_gameover():\n",
    "        val = value_from_action\n",
    "        return (best_action, val)\n",
    "\n",
    "    if my_turn:\n",
    "        # Want to maximize \n",
    "        val = float('-inf')\n",
    "        actions = game.get_valid_moves()\n",
    "        if len(actions) == 1:\n",
    "            best_action = actions[0]\n",
    "\n",
    "        for A in actions:\n",
    "            # Make the move\n",
    "            temp_game = copy.deepcopy(game)\n",
    "            \n",
    "            (reward, terminated, updated, invalid_moves, invalid_moves_made) = temp_game.swipe(action_dict[A], adversarial=False)\n",
    "            value_from_action = max(policy(tensor(encode_state(temp_game.get_flat_board()), device=device))[0]).item()\n",
    "            (tempBestMove, tempVal) = minimax(temp_game, policy, value_from_action, depth-1, not my_turn)\n",
    "\n",
    "            if tempVal > val:\n",
    "                val = tempVal\n",
    "                best_action = A\n",
    "    else:\n",
    "        # Want to minimize\n",
    "        val = float('inf')\n",
    "        actions = game.get_avaliable_spaces()\n",
    "        for tile_val in [2, 4]:\n",
    "            for A in actions:\n",
    "                # Make the move\n",
    "                row = int(A / 4)\n",
    "                col = A % 4\n",
    "                temp_game = copy.deepcopy(game)\n",
    "                temp_game.add_tile_to_board([row, col], tile_val)\n",
    "                value_from_action = max(policy(tensor(encode_state(temp_game.get_flat_board()), device=device))[0]).item()\n",
    "                (tempBestMove, tempVal) = minimax(temp_game, policy, value_from_action, depth-1, not my_turn)\n",
    "                # (tempBestMove, tempVal) = minimax(temp_game, policy, value_from_action, depth-1, not my_turn)\n",
    "\n",
    "            if tempVal < val:\n",
    "                val = tempVal\n",
    "                best_action = A   \n",
    "\n",
    "\n",
    "    return best_action, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # This file will be used to run the agent on the 2048 game\n",
    "# # The agent will be using the trained model to play the game\n",
    "\n",
    "\n",
    "\n",
    "# class ConvBlock(nn.Module):\n",
    "#     def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "#         super(ConvBlock, self).__init__()\n",
    "#         self.conv_vert = nn.Sequential(\n",
    "#             nn.Conv2d(in_channels, hidden_channels, kernel_size=(1,2), stride=1),\n",
    "#             nn.ReLU()\n",
    "#             )\n",
    "#         self.conv_horz = nn.Sequential(\n",
    "#             nn.Conv2d(in_channels, hidden_channels, kernel_size=(2,1), stride=1),\n",
    "#             nn.ReLU()\n",
    "#             )\n",
    "#         self.conv_vert2 = nn.Sequential(\n",
    "#             nn.Conv2d(hidden_channels, out_channels, kernel_size=(1,2), stride=1),\n",
    "#             nn.Flatten(),\n",
    "#             nn.ReLU()\n",
    "#             )\n",
    "#         self.conv_horz2 = nn.Sequential(\n",
    "#             nn.Conv2d(hidden_channels, out_channels, kernel_size=(2,1), stride=1),\n",
    "#             nn.Flatten(),\n",
    "#             nn.ReLU()\n",
    "#             )\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         x_vert = self.conv_vert(x)\n",
    "#         x_horz = self.conv_horz(x)\n",
    "#         x_vert2vert = self.conv_vert2(x_vert)\n",
    "#         x_vert2horz = self.conv_horz2(x_vert)\n",
    "#         x_horz2vert = self.conv_vert2(x_horz)\n",
    "#         x_horz2horz = self.conv_horz2(x_horz)\n",
    "#         return torch.cat([x_vert2vert, x_vert2horz, x_horz2vert, x_horz2horz], dim=1)\n",
    "\n",
    "# class NONSQUARE(nn.Module): # \n",
    "#     def __init__(self, HIDDEN_LAYER_1, HIDDEN_LAYER_2, OUTPUT_LAYER):\n",
    "#         super(NONSQUARE, self).__init__()\n",
    "#         self.network = nn.Sequential(\n",
    "#             ConvBlock(16, 256, 512),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Flatten(),   # Unnecessary?\n",
    "#             nn.Linear(17408, HIDDEN_LAYER_1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(HIDDEN_LAYER_1, HIDDEN_LAYER_2),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(HIDDEN_LAYER_2, OUTPUT_LAYER)\n",
    "#             )\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv_2x2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, hidden_channels, kernel_size=2, stride=1),\n",
    "            nn.ReLU()\n",
    "            )\n",
    "        self.conv_3x3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, hidden_channels, kernel_size=3, stride=1),\n",
    "            nn.ReLU()\n",
    "            )\n",
    "        self.conv_4x4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, hidden_channels, kernel_size=4, stride=1),\n",
    "            nn.Flatten(),\n",
    "            nn.ReLU()\n",
    "            )\n",
    "        self.conv_2x2_w_2x2 = nn.Sequential(\n",
    "            nn.Conv2d(hidden_channels, out_channels, kernel_size=2, stride=1),\n",
    "            nn.Flatten(),\n",
    "            nn.ReLU()\n",
    "            )\n",
    "        self.conv_3x3_w_2x2 = nn.Sequential(\n",
    "            nn.Conv2d(hidden_channels, out_channels, kernel_size=2, stride=1),\n",
    "            nn.Flatten(),\n",
    "            nn.ReLU()\n",
    "            )\n",
    "        self.flatten = nn.Flatten()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out_1x1xhid = self.conv_4x4(x)\n",
    "        hid_2x2xhid = self.conv_3x3(x)\n",
    "        hid_3x3xhid = self.conv_2x2(x)\n",
    "        out_1x1xout = self.conv_2x2_w_2x2(hid_2x2xhid)\n",
    "        out_2x2xout = self.conv_3x3_w_2x2(hid_3x3xhid)\n",
    "        return torch.cat([out_1x1xhid, self.flatten(hid_2x2xhid), out_1x1xout, out_2x2xout], dim=1)\n",
    "\n",
    "class CNN234(nn.Module): # \n",
    "    def __init__(self, HIDDEN_LAYER_1, HIDDEN_LAYER_2, OUTPUT_LAYER):\n",
    "        super(CNN234, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            ConvBlock(16, 256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),   # Unnecessary?\n",
    "            nn.Linear(3840, HIDDEN_LAYER_1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(HIDDEN_LAYER_1, HIDDEN_LAYER_2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(HIDDEN_LAYER_2, OUTPUT_LAYER)\n",
    "            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ash\\AppData\\Local\\Temp\\ipykernel_4024\\2399739718.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=device)\n",
      "C:\\Users\\Ash\\AppData\\Local\\Temp\\ipykernel_4024\\26961956.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  value_from_action = max(policy(tensor(encode_state(temp_game.get_flat_board()), device=device))[0]).item()\n",
      "C:\\Users\\Ash\\AppData\\Local\\Temp\\ipykernel_4024\\26961956.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  value_from_action = max(policy(tensor(encode_state(temp_game.get_flat_board()), device=device))[0]).item()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :  512\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 38\u001b[0m\n\u001b[0;32m     35\u001b[0m         action \u001b[38;5;241m=\u001b[39m actions\u001b[38;5;241m.\u001b[39margmax()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(game\u001b[38;5;241m.\u001b[39mget_avaliable_spaces()) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m8\u001b[39m):\n\u001b[1;32m---> 38\u001b[0m             action, val \u001b[38;5;241m=\u001b[39m \u001b[43mminimax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmy_turn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m             \u001b[38;5;66;03m# print(\"Move: \", action_dict[action], \"Value: \", val)\u001b[39;00m\n\u001b[0;32m     40\u001b[0m (reward, done, updated, invalid_actions, invalid_moves_made) \u001b[38;5;241m=\u001b[39m game\u001b[38;5;241m.\u001b[39mswipe(action_dict[action])\n",
      "Cell \u001b[1;32mIn[3], line 31\u001b[0m, in \u001b[0;36mminimax\u001b[1;34m(game, policy, value_from_action, depth, my_turn)\u001b[0m\n\u001b[0;32m     29\u001b[0m (reward, terminated, updated, invalid_moves, invalid_moves_made) \u001b[38;5;241m=\u001b[39m temp_game\u001b[38;5;241m.\u001b[39mswipe(action_dict[A], adversarial\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     30\u001b[0m value_from_action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(policy(tensor(encode_state(temp_game\u001b[38;5;241m.\u001b[39mget_flat_board()), device\u001b[38;5;241m=\u001b[39mdevice))[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m---> 31\u001b[0m (tempBestMove, tempVal) \u001b[38;5;241m=\u001b[39m \u001b[43mminimax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp_game\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_from_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmy_turn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tempVal \u001b[38;5;241m>\u001b[39m val:\n\u001b[0;32m     34\u001b[0m     val \u001b[38;5;241m=\u001b[39m tempVal\n",
      "Cell \u001b[1;32mIn[3], line 47\u001b[0m, in \u001b[0;36mminimax\u001b[1;34m(game, policy, value_from_action, depth, my_turn)\u001b[0m\n\u001b[0;32m     45\u001b[0m temp_game \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(game)\n\u001b[0;32m     46\u001b[0m temp_game\u001b[38;5;241m.\u001b[39madd_tile_to_board([row, col], tile_val)\n\u001b[1;32m---> 47\u001b[0m value_from_action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(policy(\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencode_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp_game\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_flat_board\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     48\u001b[0m (tempBestMove, tempVal) \u001b[38;5;241m=\u001b[39m minimax(temp_game, policy, value_from_action, depth\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;129;01mnot\u001b[39;00m my_turn)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# (tempBestMove, tempVal) = minimax(temp_game, policy, value_from_action, depth-1, not my_turn)\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "input_size = 16  # Assuming the input size is 16 for the 4x4 grid of the game\n",
    "output_size = 4  # Assuming there are 4 possible actions (up, down, left, right)\n",
    "\n",
    "model = CNN234(1024, 256, 4).to(device)\n",
    "\n",
    "# model.load_state_dict(torch.load('C:\\\\Users\\\\Ash\\\\OneDrive\\\\Documents\\\\School\\\\GeorgiaTech\\\\CS7643_DeepLearning\\\\Project\\\\2048_AI\\\\trained_models\\\\model_white_mono_corner_CNN234_policy_policy_weights_episode_1700.pth'))\n",
    "model.load_state_dict(torch.load('C:\\\\Users\\\\Ash\\\\OneDrive\\\\Documents\\\\School\\\\GeorgiaTech\\\\CS7643_DeepLearning\\\\Project\\\\2048_AI\\\\trained_models\\\\white_mono_corner_CNN234_policy_policy_weights_episode_1700.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Create an instance of the Game class\n",
    "#list of actions\n",
    "action_dict = {0:'U', 1:'R', 2:'D', 3:'L'}\n",
    "\n",
    "# game.board = np.array(custom_board)\n",
    "iterations = 100\n",
    "max_tiles = np.zeros([iterations])\n",
    "\n",
    "game = Game(np.random.randint(1, 100), 4, 'hs')\n",
    "for epoch in range(iterations):\n",
    "    game.reset()\n",
    "    # game.display()\n",
    "    done = False\n",
    "    invalid_actions = []\n",
    "\n",
    "    while not done:\n",
    "        # Get the state from the model\n",
    "        state = encode_state(game.get_flat_board()).flatten()\n",
    "        state = torch.tensor(state, dtype=torch.float32, device=device)\n",
    "\n",
    "        # action = random.randint(0, 3)\n",
    "        # Get the action from the model\n",
    "        with torch.no_grad():\n",
    "                actions = model(state.view(1,16,4,4))\n",
    "                for invalid in invalid_actions:\n",
    "                    actions[0, invalid] = -torch.inf\n",
    "                action = actions.argmax().item()\n",
    "\n",
    "                # if (len(game.get_avaliable_spaces()) < 8):\n",
    "                #     action, val = minimax(game, model, depth=3, my_turn=True)\n",
    "                #     # print(\"Move: \", action_dict[action], \"Value: \", val)\n",
    "        (reward, done, updated, invalid_actions, invalid_moves_made) = game.swipe(action_dict[action])\n",
    "        \n",
    "    # game.display()\n",
    "    \n",
    "    print(epoch, \": \", np.max(game.board))\n",
    "    max_tiles[epoch] = np.max(game.board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Count the frequency of each max_tile value\n",
    "max_tile_counts = np.bincount(max_tiles.astype(int))\n",
    "max_tile_counts = max_tile_counts[max_tile_counts>0]\n",
    "\n",
    "unique_max_tiles = np.unique(max_tiles)\n",
    "# Create a bar chart\n",
    "plt.bar(np.arange(len(unique_max_tiles)), max_tile_counts)\n",
    "plt.xticks(np.arange(len(unique_max_tiles)), unique_max_tiles)\n",
    "\n",
    "# Set the y-axis label\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Set the title\n",
    "plt.title('Frequency of Max Tile')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_2048",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
